#======================================================
# with gpt-4
#======================================================
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from keras.models import Sequential
from keras.layers import Dense, LSTM, Bidirectional, Dropout
from keras.preprocessing.sequence import pad_sequences
import openai

# Load API Key
openai.api_key = "YOUR_OPENAI_API_KEY"

# Load Dataset
def load_data(file_path):
    data = pd.read_csv(file_path)
    data = data[data['rating'].isin(['Offensive', 'Not Offensive'])]
    data['rating'] = data['rating'].map({'Offensive': 1, 'Not Offensive': 0})
    return data['comment'], data['rating']

# Extract GPT-4 Embeddings
def get_gpt4_embeddings(texts):
    embeddings = []
    for text in texts:
        try:
            response = openai.Embedding.create(input=text, model="text-embedding-ada-002")
            embeddings.append(response['data'][0]['embedding'])
        except Exception as e:
            print(f"Error with text '{text}': {e}")
            embeddings.append([0] * 1536)  # GPT-4 embedding size
    return np.array(embeddings)

# ML Models
def train_ml_models(X_train, y_train, X_test, y_test):
    models = {
        'Logistic Regression': LogisticRegression(max_iter=1000),
        'SVM': SVC(kernel='linear', probability=True),
        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)
    }
    
    results = {}
    for name, model in models.items():
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        results[name] = classification_report(y_test, predictions, output_dict=True)
        print(f"\n{name} Results:")
        print(classification_report(y_test, predictions, target_names=['Not Offensive', 'Offensive']))
    return results

# Bi-LSTM Model
def train_bilstm_model(X_train, y_train, X_test, y_test, input_dim):
    model = Sequential([
        Dense(256, input_dim=input_dim, activation='relu'),
        Dropout(0.3),
        Dense(128, activation='relu'),
        Dropout(0.3),
        Dense(1, activation='sigmoid')
    ])
    
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))
    predictions = (model.predict(X_test) > 0.5).astype("int32")
    
    print("\nBi-LSTM Results:")
    print(classification_report(y_test, predictions, target_names=['Not Offensive', 'Offensive']))
    return classification_report(y_test, predictions, output_dict=True)

# Main Function
def main():
    # Load and preprocess data
    comments, labels = load_data('dataset.csv')
    comments_train, comments_test, y_train, y_test = train_test_split(
        comments, labels, test_size=0.2, random_state=42, stratify=labels
    )

    # Get GPT-4 embeddings
    print("Generating GPT-4 embeddings for training data...")
    X_train = get_gpt4_embeddings(comments_train)
    print("Generating GPT-4 embeddings for testing data...")
    X_test = get_gpt4_embeddings(comments_test)

    # Train ML models
    print("\nTraining ML models...")
    ml_results = train_ml_models(X_train, y_train, X_test, y_test)

    # Train Bi-LSTM model
    print("\nTraining Bi-LSTM model...")
    dl_results = train_bilstm_model(X_train, y_train, X_test, y_test, input_dim=X_train.shape[1])

    # Summarize results
    print("\nResults Summary:")
    for name, result in ml_results.items():
        print(f"\n{name} - F1-Score: {result['macro avg']['f1-score']:.2f}")
    print(f"\nBi-LSTM - F1-Score: {dl_results['macro avg']['f1-score']:.2f}")

if __name__ == "__main__":
    main()

#======================================================
